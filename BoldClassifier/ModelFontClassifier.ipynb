{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7724da9f",
   "metadata": {},
   "source": [
    "### Code for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc7645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import RenderedTextGenerator\n",
    "from model import *\n",
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, img_as_float\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d7a75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator(Dataset):\n",
    "    def __init__(self, text_generator, transform=None, num_words : int = 8):\n",
    "        super(DatasetGenerator, self).__init__()\n",
    "        self.text_generator = text_generator\n",
    "        self.transform = transform\n",
    "        self.num_words = num_words\n",
    "        \n",
    "    def __len__(self):\n",
    "        return 124\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        imgs, labels = self.text_generator.render_text()\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            return torch.stack(\n",
    "                [self.transform(image = imgs[i, :, :, :3])['image'].float() for i in range(self.num_words)]), torch.tensor(labels)\n",
    "        \n",
    "        return torch.tensor(imgs), torch.tensor(labels)\n",
    "    \n",
    "def worker_init_fn(worker_id):\n",
    "    torch_seed = torch.initial_seed()\n",
    "    if torch_seed >= 2**30:  # make sure torch_seed + workder_id < 2**32\n",
    "        torch_seed = torch_seed % 2**30\n",
    "    random.seed(torch_seed + worker_id)\n",
    "    np.random.seed(torch_seed + worker_id)\n",
    "    \n",
    "    \n",
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = torch.tensor([0.])\n",
    "                    loss = loss.to(device)\n",
    "                    for i in range(outputs.shape[0]):\n",
    "                        loss += criterion(outputs[i], labels[i])#C\n",
    "                        \n",
    "                    _, preds = torch.max(outputs, 2)\n",
    "                    #print(preds)\n",
    "                        \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset) / 8\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                pass\n",
    "                val_acc_history.append(epoch_acc.detach().cpu().clone().numpy())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a470d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtg = RenderedTextGenerator(batch_size=1, fontsize_range=(10, 22), fonts_folder='fonts/', img_shape=(224, 224),\n",
    "                            fonttype='bold')\n",
    "\n",
    "input_size = 224\n",
    "train_transform = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit = 0.05, scale_limit = 0.05, rotate_limit = 0.05, p = 0.5),\n",
    "    A.SmallestMaxSize(max_size=input_size),\n",
    "    #A.RandomCrop(height=input_size, width=input_size),\n",
    "    A.RGBShift(r_shift_limit=0.7, g_shift_limit=0.7, b_shift_limit=0.7, p = 0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "dataset_gen = DatasetGenerator(rtg, train_transform)\n",
    "\n",
    "val_transform = A.Compose([\n",
    "        A.SmallestMaxSize(max_size=input_size),\n",
    "        #A.CenterCrop(height=input_size, width=input_size),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), \n",
    "        ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_dataset_gen = DatasetGenerator(rtg, val_transform)\n",
    "\n",
    "train_dataloader = DataLoader(dataset_gen, batch_size=16,worker_init_fn=worker_init_fn)\n",
    "val_dataloader = DataLoader(val_dataset_gen, batch_size=16, worker_init_fn=worker_init_fn)\n",
    "\n",
    "dataloaders_dict = {'train' : train_dataloader,\n",
    "                  'val': val_dataloader\n",
    "}\n",
    "\n",
    "model = BoldClassifier() \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbd424c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 13.7497 Acc: 0.6724\n",
      "val Loss: 13.8393 Acc: 0.6593\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 5.0356 Acc: 0.8438\n",
      "val Loss: 11.9902 Acc: 0.8377\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 4.2193 Acc: 0.8952\n",
      "val Loss: 8.2223 Acc: 0.8871\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 3.0782 Acc: 0.9294\n",
      "val Loss: 2.3109 Acc: 0.9415\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 2.4626 Acc: 0.9405\n",
      "val Loss: 20.9275 Acc: 0.4778\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 2.0894 Acc: 0.9446\n",
      "val Loss: 3.3251 Acc: 0.9163\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 2.4161 Acc: 0.9345\n",
      "val Loss: 7.9205 Acc: 0.7933\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 2.6560 Acc: 0.9294\n",
      "val Loss: 4.0781 Acc: 0.9153\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 2.6494 Acc: 0.9425\n",
      "val Loss: 2.7649 Acc: 0.9415\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 2.2391 Acc: 0.9365\n",
      "val Loss: 1.6715 Acc: 0.9536\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 3.6311 Acc: 0.9183\n",
      "val Loss: 2.6948 Acc: 0.9073\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 2.4560 Acc: 0.9375\n",
      "val Loss: 2.6235 Acc: 0.9264\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 1.8506 Acc: 0.9556\n",
      "val Loss: 2.2992 Acc: 0.9597\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 1.1142 Acc: 0.9778\n",
      "val Loss: 2.6970 Acc: 0.9395\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 1.0875 Acc: 0.9748\n",
      "val Loss: 1.0215 Acc: 0.9738\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 1.4051 Acc: 0.9657\n",
      "val Loss: 0.7720 Acc: 0.9859\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.9418 Acc: 0.9808\n",
      "val Loss: 1.7308 Acc: 0.9587\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 1.7672 Acc: 0.9597\n",
      "val Loss: 2.7046 Acc: 0.9304\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 1.3119 Acc: 0.9688\n",
      "val Loss: 1.2089 Acc: 0.9778\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 1.5136 Acc: 0.9718\n",
      "val Loss: 2.2633 Acc: 0.9415\n",
      "\n",
      "Training complete in 6m 12s\n",
      "Best val Acc: 0.985887\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device).float()\n",
    "model, history= train_model(model,\n",
    "                              dataloaders_dict, \n",
    "                              criterion,\n",
    "                              optimizer,\n",
    "                              num_epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da6ba410",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "model = BoldClassifier()\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "model = model.to(device).float()\n",
    "test_transform = A.Compose([\n",
    "        A.SmallestMaxSize(max_size=input_size),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "])\n",
    "\n",
    "test_dataset_gen = DatasetGenerator(rtg, test_transform)\n",
    "test_dataloader = DataLoader(test_dataset_gen, batch_size=10, worker_init_fn=worker_init_fn)\n",
    "\n",
    "for imgs, labels in test_dataloader:\n",
    "    imgs = imgs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    out = model(imgs)\n",
    "    _, res = torch.max(out, dim = 2)\n",
    "    print(torch.sum(res == labels).float() / (res.shape[0] * res.shape[1]))\n",
    "''';"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
