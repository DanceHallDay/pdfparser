{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7724da9f",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc7645a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_generator import *\n",
    "from model import *\n",
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import io, img_as_float\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from collections import defaultdict\n",
    "import random\n",
    "#-----------------------\n",
    "from const import VOCABS\n",
    "from Font import Font\n",
    "from WordGenerator import WordGenerator\n",
    "from WordRenderer import WordRenderer\n",
    "#-----------------------\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ba7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualAugmenterNothing(IVisualAugmenter):\n",
    "    def augment(self, img: np.array, *args, **kwrgs) -> np.array:\n",
    "        return np.array(img).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19817657",
   "metadata": {},
   "source": [
    "#### Function for creating fotns dict. Dict's key is font name without modifications(without bold, italic and e.t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb1f23e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fonts_dict(fonts_folder) -> Dict[str, Union[List[IFont], np.array]]:\n",
    "    fonts_path = [f'{fonts_folder}/{fontname}' for fontname in os.listdir(fonts_folder)]\n",
    "    fonts_dict = defaultdict(list)\n",
    "    fonts = defaultdict(list)\n",
    "    for i in range(len(fonts_path)):\n",
    "        font = Font()\n",
    "        font.load_font(fonts_path[i])\n",
    "        font_name = os.path.basename(fonts_path[i])\n",
    "        fonts_dict[font_name[:font_name.find('_')]].append(font)\n",
    "    for key in fonts_dict.keys():\n",
    "        fonts[key] = [\n",
    "            fonts_dict[key],\n",
    "            np.ones(len(fonts_dict[key])) / len(fonts_dict[key])\n",
    "        ]\n",
    "    return fonts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342c938",
   "metadata": {},
   "source": [
    "#### Random seed for torch workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102df40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    torch_seed = torch.initial_seed()\n",
    "    if torch_seed >= 2**30:  # make sure torch_seed + workder_id < 2**32\n",
    "        torch_seed = torch_seed % 2**30\n",
    "    random.seed(torch_seed + worker_id)\n",
    "    np.random.seed(torch_seed + worker_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be4937",
   "metadata": {},
   "source": [
    "#### Training finction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d7a75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  \n",
    "            else:\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = torch.tensor([0.])\n",
    "                    loss = loss.to(device)\n",
    "                    for i in range(outputs.shape[0]):\n",
    "                        loss += criterion(outputs[i], labels[i])#C\n",
    "                        \n",
    "                    _, preds = torch.max(outputs, 2)\n",
    "                    #print(\"Preds is: \",preds)\n",
    "                    #print(\"Labels is :\", labels)\n",
    "                        \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset) / 32\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                pass\n",
    "                val_acc_history.append(epoch_acc.detach().cpu().clone().numpy())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f2cf3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ivan/pdfparser-3\n",
      "/home/ivan/pdfparser-3/DataGenerator/fonts\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%cd DataGenerator/fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb4a23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = VOCABS['french']\n",
    "fonts_folder = '/home/ivan/pdfparser-3/DataGenerator/fonts'\n",
    "fonts = create_fonts_dict(fonts_folder)\n",
    "word_generator = WordGenerator()\n",
    "word_generator.word_storage_load('/home/ivan/pdfparser-3/DataGenerator/word_storage/wiki_qa_corpus/wiki_qa.wl',vocab)\n",
    "word_renderer = WordRenderer()\n",
    "text_generator = SequenceGenerator(\n",
    "    fonts= fonts,#(fonts, np.ones((len(fonts))) / len(fonts)),\n",
    "    font_sizes= ([x for x in range(10, 20)], np.ones(10) / 10),\n",
    "    augmenters= [VisualAugmenterNothing()],\n",
    "    word_generator= word_generator,\n",
    "    word_renderer= word_renderer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a470d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "train_transform = A.Compose([\n",
    "    A.ShiftScaleRotate(shift_limit = 0.05, scale_limit = 0.05, rotate_limit = 0.05, p = 0.5),\n",
    "    A.SmallestMaxSize(max_size=input_size),\n",
    "    #A.RandomCrop(height=input_size, width=input_size),\n",
    "    A.RGBShift(r_shift_limit=0.7, g_shift_limit=0.7, b_shift_limit=0.7, p = 0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "dataset_gen = DatasetGenerator(text_generator, train_transform)\n",
    "\n",
    "val_transform = A.Compose([\n",
    "        A.SmallestMaxSize(max_size=input_size),\n",
    "        #A.CenterCrop(height=input_size, width=input_size),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), \n",
    "        ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_dataset_gen = DatasetGenerator(text_generator, val_transform)\n",
    "\n",
    "train_dataloader = DataLoader(dataset_gen, batch_size=4,worker_init_fn=worker_init_fn)\n",
    "val_dataloader = DataLoader(val_dataset_gen, batch_size=4, worker_init_fn=worker_init_fn)\n",
    "\n",
    "dataloaders_dict = {'train' : train_dataloader,\n",
    "                  'val': val_dataloader\n",
    "}\n",
    "\n",
    "model = BoldClassifier() \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fbd424c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 1.6329 Acc: 0.8413\n",
      "val Loss: 9.6473 Acc: 0.7329\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.5553 Acc: 0.9458\n",
      "val Loss: 0.5959 Acc: 0.9546\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.3621 Acc: 0.9692\n",
      "val Loss: 0.8502 Acc: 0.9219\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.3136 Acc: 0.9736\n",
      "val Loss: 0.8784 Acc: 0.9512\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.2378 Acc: 0.9800\n",
      "val Loss: 0.9507 Acc: 0.9258\n",
      "\n",
      "Training complete in 9m 2s\n",
      "Best val Acc: 0.954590\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device).float()\n",
    "model, history= train_model(model,\n",
    "                              dataloaders_dict, \n",
    "                              criterion,\n",
    "                              optimizer,\n",
    "                              num_epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c061ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ivan/pdfparser-3/DataGenerator\n",
      "/home/ivan/pdfparser-3\n",
      "/home/ivan/pdfparser-3/BoldClassifier\n"
     ]
    }
   ],
   "source": [
    "#text_generator.generate_sequence(32)\n",
    "%cd ..\n",
    "%cd ..\n",
    "%cd BoldClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8ab56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), 'model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
